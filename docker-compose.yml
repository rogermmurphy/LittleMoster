version: '3.8'

services:
  # Redis for caching and session management
  redis:
    image: redis:7-alpine
    container_name: lm-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    networks:
      - lm-network

  # PostgreSQL (local development backup to Supabase)
  postgres:
    image: postgres:15-alpine
    container_name: lm-postgres
    environment:
      POSTGRES_DB: lm_dev
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - lm-network

  # Adminer - Database management UI
  adminer:
    image: adminer:latest
    container_name: lm-adminer
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    restart: unless-stopped
    networks:
      - lm-network
    environment:
      ADMINER_DEFAULT_SERVER: postgres

  # Qdrant - Open-source vector database for RAG (Production)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: lm-qdrant
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant-data:/qdrant/storage
    restart: unless-stopped
    networks:
      - lm-network

  # ChromaDB - Vector database for dev/debugging with MCP
  chromadb:
    image: chromadb/chroma:latest
    container_name: lm-chroma
    ports:
      - "8000:8000"  # HTTP API
    volumes:
      - chroma-data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    restart: unless-stopped
    networks:
      - lm-network

  # Ollama - Local LLM inference (GPT-OSS)
  # Running in CPU mode (remove deploy section to enable GPU if available)
  ollama:
    image: ollama/ollama:latest
    container_name: lm-ollama
    ports:
      - "11434:11434"  # Ollama API
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    networks:
      - lm-network
    # Uncomment below if you have NVIDIA GPU with drivers installed:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

volumes:
  redis-data:
    name: lm-redis-data
  postgres-data:
    name: lm-postgres-data
  qdrant-data:
    name: lm-qdrant-data
  chroma-data:
    name: lm-chroma-data
  ollama-data:
    name: lm-ollama-data

networks:
  lm-network:
    name: lm-network
    driver: bridge
